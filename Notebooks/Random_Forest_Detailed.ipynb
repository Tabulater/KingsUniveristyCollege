{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model for Predicting Wq\n",
    "\n",
    "This notebook provides a detailed walkthrough of building, training, and evaluating a Random Forest model to predict the queue waiting time \\(Wq) based on several input features. The explanations are designed to be comprehensive for university-level research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Objective\n",
    "\n",
    "The goal of this model is to predict the waiting time in a queue \\(W_q\\) using a Random Forest Regressor. The input features include:\n",
    "- \\(lambda): Arrival rate\n",
    "- \\(Lq): Average number of customers in the queue\n",
    "- \\(s): Number of servers\n",
    "- \\(mu): Service rate\n",
    "- \\(rho): Utilization factor\n",
    "\n",
    "We will preprocess the data, build the Random Forest model, train it, and evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "We start by loading the dataset and selecting the relevant features and target variable. Then, we scale the features using StandardScaler to normalize the data, which helps the model perform better.\n",
    "\n",
    "We also split the data into training and testing sets to evaluate the model's generalization."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('../dataset/dataset.csv')\n",
    "features = ['lambda', 'Lq', 's', 'mu', 'rho']\n",
    "X = data[features]\n",
    "y = data['Wq']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building and Training\n",
    "\n",
    "We build a Random Forest Regressor with 100 trees. The model is trained on the training data to learn the relationship between the input features and the target waiting time."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Build model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation Metrics and Interpretation\n",
    "\n",
    "We evaluate the model using Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE) on both training and testing sets. These metrics provide insights into the average prediction error and the variance of the errors."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print(\"RANDOM FOREST PERFORMANCE\")\n",
    "print(f\"Training: MAE: {train_mae:.4f}, MSE: {train_mse:.4f}, RMSE: {train_rmse:.4f}\")\n",
    "print(f\"Testing:  MAE: {test_mae:.4f}, MSE: {test_mse:.4f}, RMSE: {test_rmse:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization and Analysis\n",
    "\n",
    "We visualize the actual vs predicted values for selected features on both training and testing sets. This helps us understand how well the model captures the relationships between features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the first 10 samples from the test set for consistent comparison\n",
    "comparison_indices = range(10)\n",
    "y_test_comparison = y_test.iloc[comparison_indices]\n",
    "y_test_pred_comparison = y_test_pred[comparison_indices]\n",
    "\n",
    "# Create 6 plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Convert back to original scale for plotting\n",
    "X_train_orig = scaler.inverse_transform(X_train)\n",
    "X_test_orig = scaler.inverse_transform(X_test)\n",
    "\n",
    "features_plot = ['lambda', 'Lq', 'rho']\n",
    "indices = [0, 1, 4]\n",
    "\n",
    "for row, (name, X_data, y_actual, y_pred) in enumerate([\n",
    "    ('Training', X_train_orig, y_train, y_train_pred),\n",
    "    ('Testing', X_test_orig, y_test, y_test_pred)\n",
    "]):\n",
    "    for col, (feature, idx) in enumerate(zip(features_plot, indices)):\n",
    "        ax = axes[row, col]\n",
    "        ax.scatter(X_data[:, idx], y_actual, alpha=0.6, color='blue', label='Actual', s=20)\n",
    "        ax.scatter(X_data[:, idx], y_pred, alpha=0.6, color='red', label='Predicted', s=20)\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel('Wq')\n",
    "        ax.set_title(f'{name}: Wq vs {feature}')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sample Predictions Comparison\n",
    "\n",
    "We compare the actual and predicted \\(W_q\\) values for the first 10 samples in the test set to observe the prediction accuracy on individual data points."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual_Wq': y_test_comparison,\n",
    "    'Predicted_Wq': y_test_pred_comparison,\n",
    "    'Difference': np.abs(y_test_comparison - y_test_pred_comparison)\n",
    "})\n",
    "print(comparison.to_string(index=False))"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
