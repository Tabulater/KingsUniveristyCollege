{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model for Predicting Wq\n",
    "\n",
    "This notebook provides a detailed walkthrough of building, training, and evaluating a Neural Network model to predict the queue waiting time \\(Wq) based on several input features. The explanations are designed to be comprehensive for university-level research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction and Objective\n",
    "\n",
    "The goal of this model is to predict the waiting time in a queue \\(W_q\\) using a Neural Network. The input features include:\n",
    "- \\(lambda): Arrival rate\n",
    "- \\(Lq): Average number of customers in the queue\n",
    "- \\(s): Number of servers\n",
    "- \\(mu): Service rate\n",
    "- \\(rho): Utilization factor\n",
    "\n",
    "We will preprocess the data, build a simple feedforward neural network, train it, and evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "We start by loading the dataset and selecting the relevant features and target variable. Then, we scale the features using StandardScaler to normalize the data, which helps the neural network train more effectively.\n",
    "\n",
    "We also split the data into training and testing sets to evaluate the model's generalization."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('../dataset/dataset.csv')\n",
    "features = ['lambda', 'Lq', 's', 'mu', 'rho']\n",
    "X = data[features]\n",
    "y = data['Wq']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture and Training\n",
    "\n",
    "We build a simple feedforward neural network with two hidden layers using TensorFlow Keras. The output layer uses a softplus activation to ensure positive predictions, as waiting times cannot be negative.\n",
    "\n",
    "The model is compiled with the Adam optimizer and mean squared error loss function, and trained for 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "# Build model\n",
    "model = Sequential([\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='softplus')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation Metrics and Interpretation\n",
    "\n",
    "We evaluate the model using Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE) on both training and testing sets. These metrics provide insights into the average prediction error and the variance of the errors."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = model.predict(X_train).flatten()\n",
    "y_test_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print(\"NEURAL NETWORK PERFORMANCE\")\n",
    "print(f\"Training: MAE: {train_mae:.4f}, MSE: {train_mse:.4f}, RMSE: {train_rmse:.4f}\")\n",
    "print(f\"Testing:  MAE: {test_mae:.4f}, MSE: {test_mse:.4f}, RMSE: {test_rmse:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization and Analysis\n",
    "\n",
    "We visualize the actual vs predicted values for selected features on both training and testing sets. This helps us understand how well the model captures the relationships between features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the first 10 samples from the test set for consistent comparison\n",
    "comparison_indices = range(10)\n",
    "y_test_comparison = y_test.iloc[comparison_indices]\n",
    "y_test_pred_comparison = y_test_pred[comparison_indices]\n",
    "\n",
    "# Create 6 plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Convert back to original scale for plotting\n",
    "X_train_orig = scaler.inverse_transform(X_train)\n",
    "X_test_orig = scaler.inverse_transform(X_test)\n",
    "\n",
    "features_plot = ['lambda', 'Lq', 'rho']\n",
    "indices = [0, 1, 4]\n",
    "\n",
    "for row, (name, X_data, y_actual, y_pred) in enumerate([\n",
    "    ('Training', X_train_orig, y_train, y_train_pred),\n",
    "    ('Testing', X_test_orig, y_test, y_test_pred)\n",
    "]):\n",
    "    for col, (feature, idx) in enumerate(zip(features_plot, indices)):\n",
    "        ax = axes[row, col]\n",
    "        ax.scatter(X_data[:, idx], y_actual, alpha=0.6, color='blue', label='Actual', s=20)\n",
    "        ax.scatter(X_data[:, idx], y_pred, alpha=0.6, color='red', label='Predicted', s=20)\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel('Wq')\n",
    "        ax.set_title(f'{name}: Wq vs {feature}')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sample Predictions Comparison\n",
    "\n",
    "We compare the actual and predicted \\(W_q\\) values for the first 10 samples in the test set to observe the prediction accuracy on individual data points."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Actual_Wq': y_test_comparison,\n",
    "    'Predicted_Wq': y_test_pred_comparison,\n",
    "    'Difference': np.abs(y_test_comparison - y_test_pred_comparison)\n",
    "})\n",
    "print(comparison.to_string(index=False))"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
